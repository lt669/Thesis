\documentclass[../../main.tex]{subfiles}

 \lhead{Background}
 
\begin{document}

\section{Background}

	%The following section provides the relevant background information that form the basis of the project described in this paper.

	The project described in this paper aims to extend the functionality of a currently implemented system called the Virtual Singing Studio situated in the listening space of the Audio Lab at the University of York. The system allows a user to hear themselves as though they are present in another acoustic environment. This project looks into extending this functionality to allow the user to move themselves around a digitally modelled version of Hendrix Hall, one of the lecture halls on the Universities campus by generation a large grid of synthetic room impulse responses, using room acoustic simulation software Odeon.

	The following section covers material that forms the basis of the system produced as a result of this project.

	% This section will be split into two parts: \textbf{Pre-project}, covering material that forms the basis of the existing system upon which this project will extend upon, and \textbf{Project}, covering extra material which is specific to the extension of the current system.


%-------------Virtual Acoustic Environments-------------%
	\subsection{Virtual Acoustic Environments}

		 Virtual acoustics has been previously described \cite{Huopaniemi2000} as follows: \textit{``Virtual acoustics is a general term for the modelling of acoustical phenomena and systems with the aid of a computer''}

		By this definition, a \ac{VAE} can be thought of as an environment (such as a room) for which the acoustical phenomena have been either recreated or synthesised. To produce a \ac{VAE}, prior knowledge regarding the room which is to be acoustically recreated must be known; how do all audible frequencies propagate around the room for a set sound source location and receiver location?

		This information can be gathered by taking a \ac{RIR} and used to recreate the acoustics of a room for the set sound source and receiver location.

		%  To produce a \ac{VAE}, prior knowledge regarding the sound source, room geometry and listener are required \cite{Huopaniemi2000}.

		%  An example of a \ac{VAE} can be found in previous projects such as \cite{Brereton2012}, upon which this project is based.

		% This essentially means reproducing sounds in an environment other than the one the sound were originally present. However, it can be said that it is possible to produce a \ac{VAE}'s using non-physical methods and could also be rendered through headphones depending on the technique used to capture the 

		% Essentially, \ac{VAE}'s make it sound like someone is in an environment that they're actually not in by producing sound waves that would be present if the they were actually present in that environment. These sound waves can actually be reproduced over headphones as well as loudspeakers, depending on the method used to either capture or synthesise the sound field.

%-------------Room Impulse Responses-------------%
		\subsection{Room Impulse Responses}
			% In order to reproduce the acoustical phenomena of a room, a description of how all audible frequencies interact with that room must be obtained. This can be done by capturing a \ac{RIR}. By placing a sound source and a receiver (microphone) in said room and exciting all audible frequencies, 

			In order to reproduce the acoustical phenomena of a room, an \ac{RIR} must be obtained. This is done by exciting all audible frequencies within the room by using a sound source such as a loudspeaker, and recording the result using a receiver microphone.

			There are a number of techniques used for exciting all audible frequencies. These include an \textbf{impulse} (such as a starter pistol) or an \textbf{exponentially swept sine} for which a sine wave is exponentially increased in frequency over a fixed period of time. Using a starter pistol means that no post processing is required as all the frequencies are excited at the same time and the impulse recorded at the receiver position can be used for convolution with an audio source. Using an exponentially swept sine requires post processing in order to time align all of the frequency dependent room reflections, thus producing an impulse response through the use of a deconvolution algorithm, however this method produces a greater signal to noise ratio thus is the desired method \cite{Stan2002}. 

			Though using an omni-directional microphone to record an \ac{RIR} is a set standard \cite{ISO}, it is also possible to record \ac{RIR}'s using techniques such as Ambisonics to capture a three dimensional sound field.

		\subsection{Synthetic Room Impulse Responses in ODEON}

			A method for measuring \ac{RIR}'s has been discussed, however there is also a way to synthesis \ac{RIR}'s by using room acoustic simulation software such as Odeon \cite{odeon}.

				Odeon was designed to provide reliable predictions of room acoustics by using a hybrid of two geometric acoustic models, Ray-tracing and the \ac{ISM} to synthesis \ac{RIR}'s. These methods model how sound would propagate around a room as though it were a straight line (ray). This inherently neglects wave phenomena such as phase and diffraction, properties that are negligible at high frequencies, however they are fundamental in describing low frequency wave behaviour \cite{Siltanen2010}. Therefore geometrical methods are not accurate at modelling sound propagation for low frequency waves.

				The reason for Odeon using a hybrid of the two method comes from the inherent problems encountered in each method.

			\subsubsection{Ray-Tracing}
				The ray-tracing method imitates a sound source by emitting a large number of particles in various directions from a single point \cite{Rindel1995}. These particles are then traced around the room, losing energy each time the particle encounters a surface according to the absorption coefficient assigned to that surface. The angle at which the particle is then reflected is determined by the scattering coefficient assigned to the surface of contact, ranging from a specular reflection to a completely random reflection \cite{odeonManual}. For a specific receiver position, an area around said point is defined in which rays are collected and used to calculate the results.

				Ray-tracing does not provide a completely accurate result as it is a risk that some rays may not pass close enough to the receiver to contribute to the final result. The outcome of the ray-tracing method is a statistical result rather than a complete one.

			\subsubsection{Image Source Method}
			
				%The \ac{ISM} represents specular reflections from surfaces as its own source, mirroring that of the original sound source, creating what is known as ``image sources'' \cite{Rindel1995} and can be used to find all possible specular reflection paths. Figure~\ref{ISMPic} illustrates this concept. The advantage of the \ac{ISM} is that each surface can be modelled by an image source which provides a great deal of data regarding the contribution to the received sound making this method more accurate than ray-tracing.

				The \ac{ISM} can be used to find all possible specular reflections paths from the sound source to the receiver position. This is done by representing each specular reflection from a surface as a secondary source known as an ``image source'' \cite{Rindel1995}, illustrated in figure~\ref{ISMPic}. The advantage of the \ac{ISM} is that each surface can be modelled by an image source which provides a great deal of data regarding the contribution to the received sound making this method more accurate than ray-tracing, however as each image source then emits more rays there is a possibility to produce a great deal more image sources. This means that the number of image sources grows exponentially for each new image source than is produced making this method much more computationally expensive than the ray-tracing method. This problem can be avoided by setting a \textit{reflection order} which determines how many times a ray can reflect off a surface before calculations are stopped, thus preventing the creation of more image source though the calculates for the prediction of the rooms acoustics will be incomplete. This obviously then makes the \ac{ISM} less accurate with a smaller reflection order.

				Once all image sources have been calculated, a visibility check is run. This checks to see whether the image sources that have been produced can be seen by the receiver, therefore checking whether that image source needs to be used or not. If the image source is not in sight of the receiver, it therefore does not need to be used for calculations. If the receiver position is moved, the visibility check is run again. Overall, this saves time as the image sources do not need to be recalculated.


				\begin{figure}[ht]
					\center\includegraphics[scale = 0.3]{Sections/Background/images/ISM.png}
					\caption{Illustration of the image source method (by the author)}
					\label{ISMPic}
				\end{figure}

			\subsubsection{Hybrid Method}
				%The inherent problems of the ray-tracing method and the \ac{ISM} are occluded by using a hybrid method that uses the best part of both. 

				Ideally, the \ac{ISM} would be used to calculate all sound rays due to its accurate results, however due to the computational limitations, Odeon uses a hybrid method to provide a reasonable compromise of calculation time and accuracy.

				The hybrid method first uses the \ac{ISM} to calculate a number of image sources up until a specified reflection order determined by a \ac{TO}. For example, if the \ac{TO} = 2, the image source method will allow a ray to reflect twice which will produce a number of image sources, then it will switch to using the ray tracing method to calculate a statistical model of how the rest of the rays might propagate. Therefore, the early part of the calculated synthetic impulse response is accurate, and they 



%-------------Ambisonics-------------%
		\subsection{Ambisonics}

			Ambisonics is a technique used to encode and decode three dimensional spatial audio information using just four audio channels. A three dimensional sound field can be recorded using a microphone known as a Soundfield microphone shown on the left in figure~\ref{sfMic}. These microphones contain four coincident capsules, one of which is an omni-directional capsule (W) and the rest of which are figure of 8 capsules used to record sound in the X (front and back), Y (left and right) and Z (up and down) direction illustrated on the right in figure~\ref{sfMic}. By combining these signals in what is known as a B-Format audio file, the sound field surrounding the microphone can be captured. By using a system specific Ambisonic decoder, the soundfield can be accurately reconstructed by replaying the B-Format file over a spherical loudspeaker array of arbitrary size.

			%-------------Soundfield mic images-------------%
			\begin{figure}[ht]
				\begin{minipage}{0.5\textwidth}
					\center\includegraphics[scale = 0.2]{Sections/Background/images/soudFieldMic.jpg}
				\end{minipage}
				\begin{minipage}{0.5\textwidth}
					\center\includegraphics[scale = 0.3]{Sections/Background/images/soundFieldPolar.jpg}
				\end{minipage}
				\caption{\textbf{Left}: Picture of a Soundfield microphone with coincident capsules exposed \textbf{Right}: Soundfield microphone polar pattern \cite{soundFieldMic}}
				\label{sfMic}
			\end{figure}

	\subsection{The Virtual Singing Studio}

		The \ac{VSS} is a loudspeaker based room acoustics simulator used as a tool for analysing the correlation between room acoustic characteristics and vocal performance parameters as part of Dr Jude Breretons PhD Thesis \cite{Brereton2014}. It is comprised of a head-mounted microphone used to capture a real-time audio input from a singer, a software patch that convolves the audio signal with a number of Ambisonic B-Format \ac{RIR}'s and finally a spherical array of 16 loudspeakers for which the convolved audio signal is decoded and fed to. In addition, a head-tracking device (an Oculus Rift \cite{oculus}) is also used to track which direction the user is facing in the virtual space. A flow diagram of the system can is shown in figure~\ref{vssDiagram}.

		The \ac{VAE} used in the \ac{VSS} was initially the National Centre for Early Music, a space in York frequently used for musical performance. Using a Soundfield microphone, 16 Ambisonic B-Format \ac{RIR}'s were captured. Four positions were chosen and four \ac{RIR}'s facing in four directions (front, left, back, right) were recorded in each. These four directional \ac{RIR}'s are used to approximate the room acoustic phenomena that would occur if the user were projecting in that direction. This is done by using the data from the head-tracking device to amplitude pan the convolved signals before sending them to the spherical speaker array. Though this is a crude method for achieving such a state, it provides enough variation between the two directions to be considered convincing.

		% By convolving a real-time audio input captured from a head-mounted microphone placed on the singer with an Ambisonic B-Format \ac{RIR}, the singer can hear themselves as if they were in the simulated acoustic environment. In addition, the performer is also fitted with a head tracking device (an Oculus Rift \cite{oculus}) which allows them to turn within the virtual space, enabling them to sing and hear themselves as if they were actually singing in that direction. This is made possible by taking four \ac{RIR}'s at each desired position, one in each direction (forward, left, backwards, right) and convolving the real-time audio input with all four of them. Depending on which direction the user is facing, a mixture of two of these will be used  .

		% The \ac{VSS} allows for a performer to hear themselves as if within another room. This is ideal for accessing the performance of singers when in different acoustic environment by being able to simulate a number \ac{VAE}'s at the click of a button.



		%RIR with ambisonics

		%Live audio input with RIR

		%Max patch and .spat


		\subsection{Project Motivation}
			
			%The \ac{VSS} has addressed a problem faced by professional musical performers: travelling to performance spaces for rehearsal.

			The \ac{VSS} addressed a problem faced when trying to research how musicians preform in different acoustic environments: having to travel to each performance space with musicians and researchers. This also indirectly provides a solution for performers wanting to rehearse is spaces that are often inaccessible and would otherwise be expensive to book and travel to. By obtaining an \ac{RIR} of the desired location, the only time travelling will be necessary is to initially obtain said \ac{RIR}. However, one limitation of using the \ac{VSS} is the restriction of position. If a performer wanted to try and sing at another point in the room, an \ac{RIR} would have to be taken in that position too. This could be done initially, taking a range of \ac{RIR}'s in a number of positions, however it can not be guaranteed that all locations desirable to the performer will be available.\\

			Therefore, this project aims to implement a system that will allow the user of the \ac{VSS} to move around a \ac{VAE} freely.

			Previous projects have addressed mobility within \ac{VAE}'s before, such as \cite{Savioja1999}. The paper initially looks at two methods for providing mobility: \textit{direct room impulse response rendering} and \textit{parametric room impulse response rendering}. Direct room impulse response rendering consists of obtaining a set number of \ac{RIR}'s in a grid and interpolation between them to synthesis the users position. This method suffered from the fact that a large number of \ac{RIR}'s are required, thus the requirement for a large amount of storage space.

			Parametric room impulse response rendering actually synthesises \ac{RIR}'s in real time for the given position of the user in the \ac{VAE}, making them more accurate for the given location. This method avoids the need for a large amount of storage space and a system to retrieve the correct files, however, as will be seen through the rest of this report, post-processing of the obtained {RIR}'s is required, which would not be possible with real time rendering.

		\subsection{Similar Projects}

\paragraph{Geometrical Methods}



\end{document}